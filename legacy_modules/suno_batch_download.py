"""
Batch Download Suno Songs - T√≠ch h·ª£p v·ªõi Multi Account Manager
D·ª±a tr√™n bulk-suno-py-2 v·ªõi c·∫£i ti·∫øn cho multi-account
"""
import os
import re
import time
import json
import random
import requests
from pathlib import Path
from colorama import init, Fore, Style

# Kh·ªüi t·∫°o colorama
init(autoreset=True)

class SunoBatchDownloader:
    def __init__(self, session_token=None, proxy_list=None):
        """
        Kh·ªüi t·∫°o downloader
        
        Args:
            session_token: JWT token t·ª´ cookies (cookie __session)
            proxy_list: List c√°c proxy (optional)
        """
        self.session_token = session_token
        self.proxy_list = proxy_list or []
        self.base_url = "https://studio-api.prod.suno.com/api"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json',
        }
        
        if self.session_token:
            self.headers['Authorization'] = f'Bearer {self.session_token}'
        
        # File l∆∞u l·ªãch s·ª≠ download
        self.history_file = Path("download_history.json")
    
    def load_download_history(self, account_name):
        """Load l·ªãch s·ª≠ download c·ªßa account"""
        try:
            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
                    return history.get(account_name, {
                        'downloaded_ids': [],
                        'total_downloaded': 0,
                        'current_page': 0,
                        'last_profile': ''
                    })
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  L·ªói khi load history: {str(e)}")
        
        return {
            'downloaded_ids': [],
            'total_downloaded': 0,
            'current_page': 0,
            'last_profile': ''
        }
    
    def save_download_history(self, account_name, history_data):
        """L∆∞u l·ªãch s·ª≠ download c·ªßa account"""
        try:
            # Load to√†n b·ªô history
            all_history = {}
            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    all_history = json.load(f)
            
            # Update cho account hi·ªán t·∫°i
            all_history[account_name] = history_data
            
            # Save l·∫°i file
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(all_history, f, indent=4, ensure_ascii=False)
            
            print(f"{Fore.GREEN}‚úì ƒê√£ l∆∞u l·ªãch s·ª≠ trang {history_data.get('current_page', 0)}")
        
        except Exception as e:
            print(f"{Fore.RED}‚ùå L·ªói khi save history: {str(e)}")
    
    def get_random_proxy(self):
        """L·∫•y proxy ng·∫´u nhi√™n t·ª´ list"""
        if not self.proxy_list:
            return None
        return {'http': random.choice(self.proxy_list), 'https': random.choice(self.proxy_list)}
    
    def sanitize_filename(self, name):
        """L√†m s·∫°ch t√™n file, lo·∫°i b·ªè k√Ω t·ª± kh√¥ng h·ª£p l·ªá"""
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng h·ª£p l·ªá
        invalid_chars = r'<>:"/\\|?*'
        for char in invalid_chars:
            name = name.replace(char, '')
        
        # Lo·∫°i b·ªè control characters
        name = re.sub(r'[\x00-\x1f\x7f]', '', name)
        
        # Trim spaces v√† dots ·ªü cu·ªëi
        name = name.strip().rstrip('.')
        
        # N·∫øu t√™n r·ªóng, d√πng t√™n m·∫∑c ƒë·ªãnh
        if not name:
            name = "untitled"
        
        return name
    
    def ensure_unique_filename(self, directory, base_name, extension='.mp3'):
        """ƒê·∫£m b·∫£o t√™n file kh√¥ng tr√πng l·∫∑p"""
        file_path = Path(directory) / f"{base_name}{extension}"
        
        if not file_path.exists():
            return str(file_path)
        
        counter = 2
        while True:
            new_name = f"{base_name} ({counter}){extension}"
            file_path = Path(directory) / new_name
            if not file_path.exists():
                return str(file_path)
            counter += 1
    
    def fetch_profile_clips(self, profile_name, start_page=0, max_pages=None):
        """
        L·∫•y clips t·ª´ profile theo page
        
        Args:
            profile_name: T√™n profile (VD: @username)
            start_page: Trang b·∫Øt ƒë·∫ßu (0-indexed)
            max_pages: S·ªë trang t·ªëi ƒëa c·∫ßn fetch (None = kh√¥ng gi·ªõi h·∫°n)
        
        Returns:
            Tuple (clips_list, last_page, has_more)
        """
        print(f"\n{Fore.CYAN}üì• ƒêang l·∫•y clips t·ª´ profile: {profile_name} (b·∫Øt ƒë·∫ßu t·ª´ trang {start_page})")
        
        # B·ªè @ n·∫øu c√≥
        if profile_name.startswith('@'):
            profile_name = profile_name[1:]
        
        url = f"{self.base_url}/profiles/{profile_name}/clips"
        all_clips = []
        page = start_page
        retry_wait = 10
        pages_fetched = 0
        
        while True:
            # Ki·ªÉm tra gi·ªõi h·∫°n s·ªë trang
            if max_pages and pages_fetched >= max_pages:
                print(f"{Fore.YELLOW}‚ö†Ô∏è  ƒê√£ ƒë·∫°t gi·ªõi h·∫°n {max_pages} trang")
                return all_clips, page - 1, True
            
            try:
                params = {'page': page}
                proxies = self.get_random_proxy()
                
                response = requests.get(
                    url,
                    headers=self.headers,
                    params=params,
                    proxies=proxies,
                    timeout=30
                )
                
                if response.status_code == 429:
                    print(f"{Fore.YELLOW}‚ö†Ô∏è  Rate limit (429), ƒë·ª£i {retry_wait}s...")
                    time.sleep(retry_wait)
                    retry_wait = min(retry_wait + 5, 60)
                    continue
                
                response.raise_for_status()
                data = response.json()
                
                clips = data.get('clips', [])
                if not clips:
                    # Kh√¥ng c√≤n clips n·ªØa
                    print(f"{Fore.GREEN}‚úÖ ƒê√£ h·∫øt clips ·ªü trang {page}")
                    return all_clips, page - 1, False
                
                all_clips.extend(clips)
                print(f"{Fore.GREEN}‚úì Page {page}: {len(clips)} clips")
                
                page += 1
                pages_fetched += 1
                time.sleep(5)  # ƒê·ª£i gi·ªØa c√°c page
                retry_wait = 10  # Reset retry wait
                
            except requests.exceptions.RequestException as e:
                print(f"{Fore.RED}‚ùå L·ªói khi fetch page {page}: {str(e)}")
                return all_clips, page - 1, False
        
        print(f"{Fore.GREEN}‚úÖ T·ªïng c·ªông: {len(all_clips)} clips")
        return all_clips, page - 1, False
    
    def fetch_my_clips(self):
        """
        L·∫•y t·∫•t c·∫£ clips c·ªßa user hi·ªán t·∫°i (t·ª´ /me)
        
        Returns:
            List c√°c clip info
        """
        print(f"\n{Fore.CYAN}üì• ƒêang l·∫•y clips c·ªßa b·∫°n t·ª´ /me...")
        
        url = f"{self.base_url}/feed/v2"
        params = {'page': 0}
        all_clips = []
        retry_wait = 10
        
        try:
            proxies = self.get_random_proxy()
            
            response = requests.get(
                url,
                headers=self.headers,
                params=params,
                proxies=proxies,
                timeout=30
            )
            
            if response.status_code == 429:
                print(f"{Fore.YELLOW}‚ö†Ô∏è  Rate limit (429), ƒë·ª£i {retry_wait}s...")
                time.sleep(retry_wait)
                return []
            
            response.raise_for_status()
            data = response.json()
            
            # L·∫•y clips t·ª´ feed
            clips = data.get('clips', [])
            all_clips.extend(clips)
            
            print(f"{Fore.GREEN}‚úÖ T√¨m th·∫•y: {len(all_clips)} clips")
            return all_clips
            
        except requests.exceptions.RequestException as e:
            print(f"{Fore.RED}‚ùå L·ªói khi fetch clips: {str(e)}")
            return []
    
    def get_current_user_info(self):
        """
        L·∫•y th√¥ng tin user hi·ªán t·∫°i
        
        Returns:
            Dict ch·ª©a user info (username, email, etc.)
        """
        try:
            url = f"{self.base_url}/billing/info"
            proxies = self.get_random_proxy()
            
            response = requests.get(
                url,
                headers=self.headers,
                proxies=proxies,
                timeout=30
            )
            
            response.raise_for_status()
            data = response.json()
            
            # Tr√≠ch xu·∫•t username t·ª´ response
            user_info = {
                'username': data.get('display_name', ''),
                'email': data.get('email', ''),
                'credits': data.get('total_credits_left', 0)
            }
            
            print(f"{Fore.GREEN}‚úì User: @{user_info['username']}, Credits: {user_info['credits']}")
            return user_info
            
        except requests.exceptions.RequestException as e:
            print(f"{Fore.RED}‚ùå L·ªói khi l·∫•y user info: {str(e)}")
            return None
    
    def fetch_clips_by_uuids(self, uuids):
        """
        L·∫•y th√¥ng tin clips theo UUIDs
        
        Args:
            uuids: List ho·∫∑c set c√°c UUID
        
        Returns:
            List c√°c clip info
        """
        print(f"\n{Fore.CYAN}üì• ƒêang l·∫•y {len(uuids)} clips theo UUID...")
        
        clips = []
        for idx, uuid in enumerate(uuids, 1):
            try:
                url = f"{self.base_url}/clips/{uuid}"
                proxies = self.get_random_proxy()
                
                response = requests.get(
                    url,
                    headers=self.headers,
                    proxies=proxies,
                    timeout=30
                )
                
                if response.status_code == 429:
                    print(f"{Fore.YELLOW}‚ö†Ô∏è  Rate limit, ƒë·ª£i 10s...")
                    time.sleep(10)
                    response = requests.get(url, headers=self.headers, proxies=proxies, timeout=30)
                
                response.raise_for_status()
                clip_data = response.json()
                clips.append(clip_data)
                
                print(f"{Fore.GREEN}‚úì [{idx}/{len(uuids)}] {clip_data.get('title', 'Unknown')}")
                time.sleep(2)
                
            except requests.exceptions.RequestException as e:
                print(f"{Fore.RED}‚ùå L·ªói khi fetch UUID {uuid}: {str(e)}")
        
        return clips

    def fetch_my_clips_paginated(self, start_page: int = 0, max_pages: int | None = None):
        """
        Fetch clips from the user's feed (/feed/v2) across multiple pages.

        Args:
            start_page: page index to start from
            max_pages: maximum number of pages to fetch (None == all available)

        Returns:
            (all_clips, last_page, has_more)
        """
        print(f"\n{Fore.CYAN}üì• ƒêang l·∫•y clips t·ª´ /feed/v2 (create/me) ...")

        url = f"{self.base_url}/feed/v2"
        current_page = start_page
        all_clips = []
        pages_fetched = 0

        while True:
            params = {"page": current_page}
            try:
                proxies = self.get_random_proxy()
                response = requests.get(
                    url,
                    headers=self.headers,
                    params=params,
                    proxies=proxies,
                    timeout=30
                )

                if response.status_code == 429:
                    print(f"{Fore.YELLOW}‚ö†Ô∏è  Rate limit (429), ƒë·ª£i 10s...")
                    time.sleep(10)
                    continue

                response.raise_for_status()
                data = response.json()

                clips = data.get("clips", [])
                all_clips.extend(clips)

                # Determine has_more: server may include pagination metadata
                has_more = bool(data.get("has_more", False))
                # Fallback: if clips length < page size then no more
                if not has_more and len(clips) == 0:
                    has_more = False

                pages_fetched += 1

                print(f"{Fore.GREEN}‚úì Trang {current_page}: T√¨m th·∫•y {len(clips)} clips (t·ªïng: {len(all_clips)})")

                # Check stopping conditions
                if max_pages is not None and pages_fetched >= max_pages:
                    return all_clips, current_page, True

                if not has_more:
                    return all_clips, current_page, False

                current_page += 1
                time.sleep(1)

            except requests.exceptions.RequestException as e:
                print(f"{Fore.RED}‚ùå L·ªói khi fetch feed page {current_page}: {str(e)}")
                return all_clips, current_page, False
    
    def download_audio(self, clip_info, directory, append_uuid=False):
        """
        Download file audio t·ª´ clip info
        
        Args:
            clip_info: Dict ch·ª©a th√¥ng tin clip
            directory: Th∆∞ m·ª•c l∆∞u file
            append_uuid: C√≥ th√™m UUID v√†o t√™n file kh√¥ng
        
        Returns:
            Path ƒë·∫øn file ƒë√£ download ho·∫∑c None n·∫øu th·∫•t b·∫°i
        """
        title = clip_info.get('title', 'Untitled')
        clip_id = clip_info.get('id', 'unknown')
        audio_url = clip_info.get('audio_url')
        
        if not audio_url:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  Kh√¥ng c√≥ audio_url cho: {title}")
            return None
        
        # T·∫°o t√™n file
        safe_title = self.sanitize_filename(title)
        if append_uuid:
            base_name = f"{safe_title}__ID__{clip_id}"
        else:
            base_name = safe_title
        
        # ƒê·∫£m b·∫£o t√™n file unique
        file_path = self.ensure_unique_filename(directory, base_name)
        
        try:
            proxies = self.get_random_proxy()
            response = requests.get(audio_url, proxies=proxies, stream=True, timeout=60)
            response.raise_for_status()
            
            # Download file
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            file_size = os.path.getsize(file_path)
            print(f"{Fore.GREEN}‚úì Downloaded: {Path(file_path).name} ({file_size/1024/1024:.2f} MB)")
            
            return file_path
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå L·ªói khi download {title}: {str(e)}")
            if os.path.exists(file_path):
                os.remove(file_path)
            return None
    
    def download_thumbnail(self, clip_info, directory):
        """Download thumbnail/cover art"""
        image_url = clip_info.get('image_url')
        if not image_url:
            return None
        
        clip_id = clip_info.get('id', 'unknown')
        file_path = Path(directory) / f"{clip_id}_cover.jpg"
        
        try:
            proxies = self.get_random_proxy()
            response = requests.get(image_url, proxies=proxies, timeout=30)
            response.raise_for_status()
            
            with open(file_path, 'wb') as f:
                f.write(response.content)
            
            return str(file_path)
            
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  Kh√¥ng download ƒë∆∞·ª£c thumbnail: {str(e)}")
            return None
    
    def embed_metadata(self, audio_path, clip_info, thumbnail_path=None):
        """Nh√∫ng metadata v√†o file MP3"""
        try:
            from mutagen.id3 import ID3, TIT2, TPE1, TALB, TCON, TPUB, WOAR, APIC
            from mutagen.mp3 import MP3
            
            audio = MP3(audio_path, ID3=ID3)
            
            # X√≥a ID3 tags c≈© n·∫øu c√≥
            try:
                audio.delete()
            except:
                pass
            
            # T·∫°o ID3 tags m·ªõi
            audio.add_tags()
            
            # Th√™m metadata c∆° b·∫£n
            audio.tags.add(TIT2(encoding=3, text=clip_info.get('title', '')))
            
            if clip_info.get('display_name'):
                audio.tags.add(TPE1(encoding=3, text=clip_info['display_name']))
            
            if clip_info.get('metadata', {}).get('tags'):
                audio.tags.add(TCON(encoding=3, text=', '.join(clip_info['metadata']['tags'])))
            
            if clip_info.get('display_name'):
                audio.tags.add(TPUB(encoding=3, text=clip_info['display_name']))
            
            # Th√™m URL
            song_url = f"https://suno.com/song/{clip_info.get('id', '')}"
            audio.tags.add(WOAR(url=song_url))
            
            # Th√™m cover art
            if thumbnail_path and os.path.exists(thumbnail_path):
                with open(thumbnail_path, 'rb') as img:
                    audio.tags.add(
                        APIC(
                            encoding=3,
                            mime='image/jpeg',
                            type=3,  # Cover (front)
                            desc='Cover',
                            data=img.read()
                        )
                    )
            
            audio.save()
            print(f"{Fore.GREEN}‚úì ƒê√£ nh√∫ng metadata cho: {Path(audio_path).name}")
            
        except ImportError:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  mutagen ch∆∞a c√†i ƒë·∫∑t, b·ªè qua metadata")
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  L·ªói khi nh√∫ng metadata: {str(e)}")
    
    def batch_download_with_pagination(self, profile_name, directory, account_name, 
                                      max_songs_per_page=20, resume=False, 
                                      with_thumbnail=False, append_uuid=False,
                                      use_create_page: bool = False):
        """
        Batch download v·ªõi h·ªó tr·ª£ pagination v√† resume
        
        Args:
            profile_name: T√™n profile ƒë·ªÉ download (VD: @username)
            directory: Th∆∞ m·ª•c l∆∞u file
            account_name: T√™n account (ƒë·ªÉ l∆∞u history)
            max_songs_per_page: S·ªë b√†i t·ªëi ƒëa m·ªói trang (m·∫∑c ƒë·ªãnh 20)
            resume: Ti·∫øp t·ª•c t·ª´ trang ƒë√£ l∆∞u (True/False)
            with_thumbnail: Download v√† nh√∫ng thumbnail
            append_uuid: Th√™m UUID v√†o t√™n file
        
        Returns:
            Dict ch·ª©a th·ªëng k√™ download
        """
        # Load l·ªãch s·ª≠
        history = self.load_download_history(account_name)
        downloaded_ids = set(history.get('downloaded_ids', []))
        
        # X√°c ƒë·ªãnh trang b·∫Øt ƒë·∫ßu
        if resume and history.get('last_profile') == profile_name:
            start_page = history.get('current_page', 0)
            print(f"{Fore.CYAN}üîÑ Ti·∫øp t·ª•c t·ª´ trang {start_page} (ƒë√£ t·∫£i {len(downloaded_ids)} b√†i)")
        else:
            start_page = 0
            if not resume:
                # Reset history n·∫øu kh√¥ng resume
                downloaded_ids = set()
            print(f"{Fore.CYAN}üÜï B·∫Øt ƒë·∫ßu m·ªõi t·ª´ trang 0")
        
        # T·∫°o th∆∞ m·ª•c
        Path(directory).mkdir(parents=True, exist_ok=True)
        
        total_success = 0
        total_fail = 0
        current_page = start_page
        
        print(f"\n{Fore.CYAN}{'='*70}")
        print(f"{Fore.CYAN}üéµ BATCH DOWNLOAD T·ª™ PROFILE: {profile_name}")
        print(f"{Fore.CYAN}{'='*70}\n")
        
        while True:
            print(f"\n{Fore.YELLOW}üìÑ ƒêang x·ª≠ l√Ω trang {current_page}...")
            
            # Fetch clips t·ª´ trang hi·ªán t·∫°i (ch·ªâ l·∫•y 1 trang)
            if use_create_page:
                # Fetch from /feed/v2 (create or /me context)
                # fetch_my_clips_paginated returns (clips_all, last_page, has_more)
                clips_all, last_page, has_more = self.fetch_my_clips_paginated(start_page=current_page, max_pages=1)
                clips = clips_all
            else:
                clips, last_page, has_more = self.fetch_profile_clips(
                    profile_name, 
                    start_page=current_page,
                    max_pages=1
                )
            
            if not clips:
                print(f"{Fore.GREEN}‚úÖ ƒê√£ t·∫£i h·∫øt t·∫•t c·∫£ b√†i h√°t!")
                break
            
            # L·ªçc b·ªè c√°c b√†i ƒë√£ download
            new_clips = [c for c in clips if c.get('id') not in downloaded_ids]
            
            if not new_clips:
                print(f"{Fore.YELLOW}‚ö†Ô∏è  Trang {current_page}: T·∫•t c·∫£ {len(clips)} b√†i ƒë√£ ƒë∆∞·ª£c t·∫£i")
                current_page += 1
                
                # Update history
                history['current_page'] = current_page
                history['last_profile'] = profile_name
                self.save_download_history(account_name, history)
                
                if not has_more:
                    print(f"{Fore.GREEN}‚úÖ ƒê√£ h·∫øt clips!")
                    break
                continue
            
            print(f"{Fore.CYAN}üì• Trang {current_page}: {len(new_clips)}/{len(clips)} b√†i m·ªõi")
            
            # Download t·ª´ng b√†i
            page_success = 0
            page_fail = 0
            
            for idx, clip in enumerate(new_clips, 1):
                clip_id = clip.get('id')
                title = clip.get('title', 'Unknown')
                
                print(f"\n{Fore.CYAN}[{idx}/{len(new_clips)}] {title}")
                
                # Download audio
                audio_path = self.download_audio(clip, directory, append_uuid)
                
                if audio_path:
                    page_success += 1
                    total_success += 1
                    
                    # Th√™m v√†o downloaded_ids
                    downloaded_ids.add(clip_id)
                    
                    # Download thumbnail v√† nh√∫ng metadata
                    if with_thumbnail:
                        thumbnail_path = self.download_thumbnail(clip, directory)
                        self.embed_metadata(audio_path, clip, thumbnail_path)
                        
                        # X√≥a thumbnail file sau khi nh√∫ng
                        if thumbnail_path and os.path.exists(thumbnail_path):
                            os.remove(thumbnail_path)
                else:
                    page_fail += 1
                    total_fail += 1
                
                # ƒê·ª£i gi·ªØa c√°c downloads
                if idx < len(new_clips):
                    time.sleep(2)
                
                # Update history sau m·ªói b√†i th√†nh c√¥ng
                if audio_path:
                    history['downloaded_ids'] = list(downloaded_ids)
                    history['total_downloaded'] = len(downloaded_ids)
                    history['current_page'] = current_page
                    history['last_profile'] = profile_name
                    history['last_download'] = time.strftime('%Y-%m-%d %H:%M:%S')
                    self.save_download_history(account_name, history)
            
            print(f"\n{Fore.GREEN}‚úì Trang {current_page}: Th√†nh c√¥ng {page_success}/{len(new_clips)}")
            
            # Chuy·ªÉn sang trang ti·∫øp theo
            current_page += 1
            
            # Update history trang
            history['current_page'] = current_page
            history['last_profile'] = profile_name
            self.save_download_history(account_name, history)
            
            # Ki·ªÉm tra c√≤n trang n·ªØa kh√¥ng
            if not has_more:
                print(f"{Fore.GREEN}‚úÖ ƒê√£ h·∫øt clips!")
                break
            
            print(f"{Fore.YELLOW}‚û°Ô∏è  Chuy·ªÉn sang trang {current_page}...")
            time.sleep(3)  # ƒê·ª£i tr∆∞·ªõc khi fetch trang m·ªõi
        
        print(f"\n{Fore.CYAN}{'='*70}")
        print(f"{Fore.GREEN}‚úÖ HO√ÄN T·∫§T!")
        print(f"{Fore.GREEN}   T·ªïng th√†nh c√¥ng: {total_success}")
        print(f"{Fore.RED}   T·ªïng th·∫•t b·∫°i: {total_fail}")
        print(f"{Fore.CYAN}   Trang cu·ªëi: {current_page - 1}")
        print(f"{Fore.CYAN}   T·ªïng ƒë√£ t·∫£i: {len(downloaded_ids)} b√†i")
        print(f"{Fore.CYAN}{'='*70}\n")
        
        return {
            'success': total_success,
            'failed': total_fail,
            'total_downloaded': len(downloaded_ids),
            'last_page': current_page - 1
        }
    
    def batch_download(self, clips, directory, with_thumbnail=False, append_uuid=False):
        """
        Batch download nhi·ªÅu clips (ph∆∞∆°ng th·ª©c c≈© - gi·ªØ l·∫°i ƒë·ªÉ t∆∞∆°ng th√≠ch)
        
        Args:
            clips: List c√°c clip info
            directory: Th∆∞ m·ª•c l∆∞u file
            with_thumbnail: Download v√† nh√∫ng thumbnail
            append_uuid: Th√™m UUID v√†o t√™n file
        """
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
        Path(directory).mkdir(parents=True, exist_ok=True)
        
        print(f"\n{Fore.CYAN}{'='*70}")
        print(f"{Fore.CYAN}üéµ B·∫ÆT ƒê·∫¶U DOWNLOAD {len(clips)} SONGS")
        print(f"{Fore.CYAN}{'='*70}\n")
        
        success_count = 0
        fail_count = 0
        
        for idx, clip in enumerate(clips, 1):
            title = clip.get('title', 'Unknown')
            print(f"\n{Fore.CYAN}[{idx}/{len(clips)}] {title}")
            
            # Download audio
            audio_path = self.download_audio(clip, directory, append_uuid)
            
            if audio_path:
                success_count += 1
                
                # Download thumbnail v√† nh√∫ng metadata
                if with_thumbnail:
                    thumbnail_path = self.download_thumbnail(clip, directory)
                    self.embed_metadata(audio_path, clip, thumbnail_path)
                    
                    # X√≥a thumbnail file sau khi nh√∫ng
                    if thumbnail_path and os.path.exists(thumbnail_path):
                        os.remove(thumbnail_path)
            else:
                fail_count += 1
            
            # ƒê·ª£i m·ªôt ch√∫t gi·ªØa c√°c downloads
            if idx < len(clips):
                time.sleep(2)
        
        print(f"\n{Fore.CYAN}{'='*70}")
        print(f"{Fore.GREEN}‚úÖ Th√†nh c√¥ng: {success_count}")
        print(f"{Fore.RED}‚ùå Th·∫•t b·∫°i: {fail_count}")
        print(f"{Fore.CYAN}{'='*70}\n")


def main():
    """Test function - s·∫Ω ƒë∆∞·ª£c t√≠ch h·ª£p v√†o suno_multi_account.py"""
    print("Batch Downloader Test")
    print("Ch·ª©c nƒÉng n√†y s·∫Ω ƒë∆∞·ª£c t√≠ch h·ª£p v√†o suno_multi_account.py")

if __name__ == "__main__":
    main()
